{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Decision Trees â€” Overfit vs Regularize\n",
        "\n",
        "This notebook explores **model capacity** for trees.\n",
        "\n",
        "**We will look at:**\n",
        "- Depth vs performance\n",
        "- Underfit vs overfit behavior\n",
        "- Simple feature importance (with caveats)\n",
        "\n",
        "**Goal:** understand how to control tree complexity in practice."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 1. Setup and Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.metrics import f1_score\n",
        "\n",
        "sns.set_style(\"whitegrid\")\n",
        "plt.rcParams[\"figure.figsize\"] = (10, 6)\n",
        "\n",
        "from sklearn.datasets import make_classification\n",
        "\n",
        "X, y = make_classification(\n",
        "    n_samples=1000,\n",
        "    n_features=10,\n",
        "    n_informative=5,\n",
        "    n_redundant=2,\n",
        "    random_state=42,\n",
        ")\n",
        "\n",
        "df = pd.DataFrame(X, columns=[f\"feature_{i+1}\" for i in range(X.shape[1])])\n",
        "df[\"target\"] = y\n",
        "\n",
        "print(\"Shape:\", df.shape)\n",
        "print(df[\"target\"].value_counts())\n",
        "df.head()"
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
